{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Testing and CI\n",
    "\n",
    "\n",
    "The notebook contains problems about code testing and continuous integration with Travis CI.\n",
    "\n",
    "* * *\n",
    "\n",
    "Original by E Tollerud 2017 for LSSTC DSFP Session3 and AstroHackWeek, modified by B Sipocz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Set up py.test in you repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem we'll aim to get the [py.test](https://docs.pytest.org/en/latest/) testing framework up and running in the code repository you set up in the last set of problems.  We can then use it to collect and run tests of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a: Ensure py.test is installed\n",
    "\n",
    "Of course ``py.test`` must actually be installed before you can use it. The commands below should work for the Anaconda Python Distribution, but if you have some other Python installation you'll want to install `pytest` (and its coverage plugin) as directed in the install instructions for ``py.test``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: | ^C\n",
      "failed\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install pytest pytest-cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b: Ensure your repo has code suitable for unit tests\n",
    "\n",
    "Depending on what your code actually does, you might need to modify it to actually perform something testable.  For example, if all it does is print something, you might find it difficult to write an effective unit test.  Try adding a function that actually performs some operation and returns something different depending on various inputs.  That tends to be the easiest function to unit-test: one with a clear \"right\" answer in certain situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also be sure you have `cd`ed to the *root* of the repo for `pytest` to operate correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c: Add a test file with a test function\n",
    "\n",
    "The test must be part of the package and follow the convention that the file and the function begin with ``test`` to get picked up by the test collection machinery.  Inside the test function, you'll need some code that fails if the test condition fails.  The easiest way to do this is with an ``assert`` statement, which raises an error if its first argument is False.\n",
    "\n",
    "*Hint: remember that to be a valid python package, a directory must have an ``__init__.py``*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1\n",
      "/Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1/newfolder/git_test\n"
     ]
    }
   ],
   "source": [
    "%cd -0\n",
    "%cd newfolder/git_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: tests: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir tests\n",
    "!touch tests/test_something.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1/newfolder\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting git_test/tests/test_something.py\n"
     ]
    }
   ],
   "source": [
    "%%file git_test/tests/test_something.py\n",
    "\n",
    "def test_pos():\n",
    "    from git_test import do_something\n",
    "    assert type(do_something(1))==float, \"Output isn't a number\"\n",
    "    \n",
    "def test_neg():\n",
    "    from git_test import do_something\n",
    "    assert type(do_something(-1))==float, \"Output isn't a number\"\n",
    "    \n",
    "def test_str():\n",
    "    from git_test import do_something\n",
    "    assert type(do_something('a'))==float, \"Output isn't a number\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d: Run the test directly\n",
    "\n",
    "While this is not how you'd ordinarily run the tests, it's instructive to first try to execute the test *directly*, without using any fancy test framework.  If your test function just runs, all is good.  If you get an exception, the test failed (which in this case might be *good*).\n",
    "\n",
    "*Hint: you may need to use `reload` or just re-start your notebook kernel to get the cell below to recognize the changes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from git_test import do_something\n",
    "do_something(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git_test.tests import test_something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git_test import do_something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_something()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'git_test.tests.test_something' has no attribute 'test_something_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-77f1db893465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_something\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_something_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'git_test.tests.test_something' has no attribute 'test_something_func'"
     ]
    }
   ],
   "source": [
    "test_something.test_something_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1e: Run the tests with ``py.test``\n",
    "\n",
    "Once you have an example test, you can try invoking ``py.test``, which is how you should run the tests in the future.  This should yield a report that shows a dot for each test. If all you see are dots, the tests ran sucessfully.  But if there's a failure, you'll see the error, and the traceback showing where the error happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1\n"
     ]
    }
   ],
   "source": [
    "%cd -0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.6.7, pytest-3.10.0, py-1.7.0, pluggy-0.8.0\n",
      "rootdir: /Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1, inifile:\n",
      "plugins: cov-2.6.0\n",
      "collected 3 items                                                              \u001b[0m\n",
      "\n",
      "newfolder/git_test/tests/test_something.py \u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[36m                           [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m___________________________________ test_pos ___________________________________\u001b[0m\n",
      "\n",
      "\u001b[1m    def test_pos():\u001b[0m\n",
      "\u001b[1m        from git_test import do_something\u001b[0m\n",
      "\u001b[1m>       assert type(do_something(1))==float, \"Output isn't a number\"\u001b[0m\n",
      "\u001b[1m\u001b[31mE       AssertionError: Output isn't a number\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert <class 'int'> == float\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where <class 'int'> = type(6)\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where 6 = <function do_something at 0x108c368c8>(1)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mnewfolder/git_test/tests/test_something.py\u001b[0m:4: AssertionError\n",
      "\u001b[31m\u001b[1m___________________________________ test_neg ___________________________________\u001b[0m\n",
      "\n",
      "\u001b[1m    def test_neg():\u001b[0m\n",
      "\u001b[1m        from git_test import do_something\u001b[0m\n",
      "\u001b[1m>       assert type(do_something(-1))==float, \"Output isn't a number\"\u001b[0m\n",
      "\u001b[1m\u001b[31mE       AssertionError: Output isn't a number\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert <class 'int'> == float\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where <class 'int'> = type(4)\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where 4 = <function do_something at 0x108c368c8>(-1)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mnewfolder/git_test/tests/test_something.py\u001b[0m:8: AssertionError\n",
      "\u001b[31m\u001b[1m___________________________________ test_str ___________________________________\u001b[0m\n",
      "\n",
      "\u001b[1m    def test_str():\u001b[0m\n",
      "\u001b[1m        from git_test import do_something\u001b[0m\n",
      "\u001b[1m>       assert type(do_something('a'))==float, \"Output isn't a number\"\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mnewfolder/git_test/tests/test_something.py\u001b[0m:12: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "a = 'a'\n",
      "\n",
      "\u001b[1m    def do_something(a=0):\u001b[0m\n",
      "\u001b[1m>       out = a+5\u001b[0m\n",
      "\u001b[1m\u001b[31mE       TypeError: must be str, not int\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mnewfolder/git_test/code.py\u001b[0m:2: TypeError\n",
      "\u001b[31m\u001b[1m=========================== 3 failed in 0.13 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!py.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1f: Make the test fail (or succeed...)\n",
    "\n",
    "If your test failed when you ran it, you should now try to fix the test (or the code...) to make it work.  Try running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Modify your test to fail if it succeeded before, or vice versa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.6.7, pytest-3.10.0, py-1.7.0, pluggy-0.8.0\n",
      "rootdir: /Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1/newfolder, inifile:\n",
      "plugins: cov-2.6.0\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "git_test/tests/test_something.py \u001b[31mE\u001b[0m\u001b[36m                                       [100%]\u001b[0m\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "____________________ ERROR at setup of test_something_func _____________________\n",
      "file /Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1/newfolder/git_test/tests/test_something.py, line 2\n",
      "  def test_something_func(a):\n",
      "\u001b[31mE       fixture 'a' not found\u001b[0m\n",
      "\u001b[31m>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, doctest_namespace, monkeypatch, no_cover, pytestconfig, record_property, record_xml_attribute, record_xml_property, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\u001b[0m\n",
      "\u001b[31m>       use 'pytest --fixtures [testpath]' for help on them.\u001b[0m\n",
      "\n",
      "/Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1/newfolder/git_test/tests/test_something.py:2\n",
      "\u001b[31m\u001b[1m=========================== 1 error in 0.06 seconds ============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!py.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1g: Check coverage\n",
    "\n",
    "The coverage plugin we installed will let you check which lines of your code are actually run by the testing suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1/newfolder/git_test\n"
     ]
    }
   ],
   "source": [
    "%cd git_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.6.7, pytest-3.10.0, py-1.7.0, pluggy-0.8.0\n",
      "rootdir: /Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1/newfolder, inifile:\n",
      "plugins: cov-2.6.0\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "tests/test_something.py \u001b[32m.\u001b[0m\u001b[36m                                                [100%]\u001b[0m\n",
      "\n",
      "---------- coverage: platform darwin, python 3.6.7-final-0 -----------\n",
      "Name          Stmts   Miss  Cover\n",
      "---------------------------------\n",
      "__init__.py       1      0   100%\n",
      "code.py           2      0   100%\n",
      "---------------------------------\n",
      "TOTAL             3      0   100%\n",
      "\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 1 passed in 0.03 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!py.test --cov=git_test tests/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should yield a report, which you can use to decide if you need to add more tests to acheive complete coverage.  Check out the command line arguments to see if you can get a more detailed line-by-line report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Implement some unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sub-problems below each contain different unit testing complications.  Place the code from the snippets in your repository (either using an editor or the ``%%file`` trick), and write tests to ensure the correctness of the functions.  Try to achieve 100% coverage for all of them (especially to catch some hidden bugs!).\n",
    "\n",
    "Also, note that some of these examples are not really practical - that is, you wouldn't want to do this in *real* code because there's better ways to do it.  But because of that, they are good examples of where something can go subtly wrong... and therefore where you want to make tests!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a\n",
    "\n",
    "When you have a function with a default, it's wise to test both the with-default call (``function_b()``), and when you give a value (``function_b(1.2)``)\n",
    "\n",
    "*Hint: Beware of numbers that come close to 0... write your tests to accomodate floating-point errors!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1\n",
      "/Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1/newfolder\n"
     ]
    }
   ],
   "source": [
    "%cd -0\n",
    "%cd newfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing git_test/func_a.py\n"
     ]
    }
   ],
   "source": [
    "%%file git_test/func_a.py\n",
    "\n",
    "# `math` here is for *scalar* math... normally you'd use numpy but this makes it a bit simpler to debug\n",
    "\n",
    "import math \n",
    "\n",
    "inf = float('inf')  # this is a quick-and-easy way to get the \"infinity\" value \n",
    "\n",
    "def function_a(angle=180):\n",
    "    anglerad = math.radians(angle)\n",
    "    return math.sin(anglerad/2)/math.sin(anglerad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1/newfolder/git_test\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.6.7, pytest-3.10.0, py-1.7.0, pluggy-0.8.0\n",
      "rootdir: /Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1/newfolder, inifile:\n",
      "plugins: cov-2.6.0\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "tests/test_something.py \u001b[31mE\u001b[0m\u001b[36m                                                [100%]\u001b[0m\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "____________________ ERROR at setup of test_something_func _____________________\n",
      "\n",
      "self = <Package '/Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1/newfolder/git_test'>\n",
      "\n",
      "\u001b[1m    def _importtestmodule(self):\u001b[0m\n",
      "\u001b[1m        # we assume we are only called once per module\u001b[0m\n",
      "\u001b[1m        importmode = self.config.getoption(\"--import-mode\")\u001b[0m\n",
      "\u001b[1m        try:\u001b[0m\n",
      "\u001b[1m>           mod = self.fspath.pyimport(ensuresyspath=importmode)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/Users/Dan/miniconda3/envs/DSFP/lib/python3.6/site-packages/_pytest/python.py\u001b[0m:450: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = local('/Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1/newfolder/git_test/__init__.py')\n",
      "modname = 'git_test', ensuresyspath = 'prepend'\n",
      "\n",
      "\u001b[1m    def pyimport(self, modname=None, ensuresyspath=True):\u001b[0m\n",
      "\u001b[1m        \"\"\" return path as an imported python module.\u001b[0m\n",
      "\u001b[1m    \u001b[0m\n",
      "\u001b[1m        If modname is None, look for the containing package\u001b[0m\n",
      "\u001b[1m        and construct an according module name.\u001b[0m\n",
      "\u001b[1m        The module will be put/looked up in sys.modules.\u001b[0m\n",
      "\u001b[1m        if ensuresyspath is True then the root dir for importing\u001b[0m\n",
      "\u001b[1m        the file (taking __init__.py files into account) will\u001b[0m\n",
      "\u001b[1m        be prepended to sys.path if it isn't there already.\u001b[0m\n",
      "\u001b[1m        If ensuresyspath==\"append\" the root dir will be appended\u001b[0m\n",
      "\u001b[1m        if it isn't already contained in sys.path.\u001b[0m\n",
      "\u001b[1m        if ensuresyspath is False no modification of syspath happens.\u001b[0m\n",
      "\u001b[1m        \"\"\"\u001b[0m\n",
      "\u001b[1m        if not self.check():\u001b[0m\n",
      "\u001b[1m            raise py.error.ENOENT(self)\u001b[0m\n",
      "\u001b[1m    \u001b[0m\n",
      "\u001b[1m        pkgpath = None\u001b[0m\n",
      "\u001b[1m        if modname is None:\u001b[0m\n",
      "\u001b[1m            pkgpath = self.pypkgpath()\u001b[0m\n",
      "\u001b[1m            if pkgpath is not None:\u001b[0m\n",
      "\u001b[1m                pkgroot = pkgpath.dirpath()\u001b[0m\n",
      "\u001b[1m                names = self.new(ext=\"\").relto(pkgroot).split(self.sep)\u001b[0m\n",
      "\u001b[1m                if names[-1] == \"__init__\":\u001b[0m\n",
      "\u001b[1m                    names.pop()\u001b[0m\n",
      "\u001b[1m                modname = \".\".join(names)\u001b[0m\n",
      "\u001b[1m            else:\u001b[0m\n",
      "\u001b[1m                pkgroot = self.dirpath()\u001b[0m\n",
      "\u001b[1m                modname = self.purebasename\u001b[0m\n",
      "\u001b[1m    \u001b[0m\n",
      "\u001b[1m            self._ensuresyspath(ensuresyspath, pkgroot)\u001b[0m\n",
      "\u001b[1m>           __import__(modname)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/Users/Dan/miniconda3/envs/DSFP/lib/python3.6/site-packages/py/_path/local.py\u001b[0m:668: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\u001b[1m>   from .code import do_something\u001b[0m\n",
      "\u001b[1m\u001b[31mE   ImportError: cannot import name 'do_something'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m__init__.py\u001b[0m:1: ImportError\n",
      "\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "self = <CallInfo when='setup' exception: ImportError while importing test module '/Users/Dan/Documents/LSSTC-DSFP-Sessions/Se...back:\n",
      "__init__.py:1: in <module>\n",
      "    from .code import do_something\n",
      "E   ImportError: cannot import name 'do_something'>\n",
      "func = <function call_runtest_hook.<locals>.<lambda> at 0x109c35950>\n",
      "when = 'setup', treat_keyboard_interrupt_as_exception = False\n",
      "\n",
      "\u001b[1m    def __init__(self, func, when, treat_keyboard_interrupt_as_exception=False):\u001b[0m\n",
      "\u001b[1m        #: context of invocation: one of \"setup\", \"call\",\u001b[0m\n",
      "\u001b[1m        #: \"teardown\", \"memocollect\"\u001b[0m\n",
      "\u001b[1m        self.when = when\u001b[0m\n",
      "\u001b[1m        self.start = time()\u001b[0m\n",
      "\u001b[1m        try:\u001b[0m\n",
      "\u001b[1m>           self.result = func()\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/Users/Dan/miniconda3/envs/DSFP/lib/python3.6/site-packages/_pytest/runner.py\u001b[0m:212: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/Users/Dan/miniconda3/envs/DSFP/lib/python3.6/site-packages/_pytest/runner.py\u001b[0m:194: in <lambda>\n",
      "\u001b[1m    lambda: ihook(item=item, **kwds),\u001b[0m\n",
      "\u001b[1m\u001b[31m/Users/Dan/miniconda3/envs/DSFP/lib/python3.6/site-packages/pluggy/hooks.py\u001b[0m:284: in __call__\n",
      "\u001b[1m    return self._hookexec(self, self.get_hookimpls(), kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31m/Users/Dan/miniconda3/envs/DSFP/lib/python3.6/site-packages/pluggy/manager.py\u001b[0m:67: in _hookexec\n",
      "\u001b[1m    return self._inner_hookexec(hook, methods, kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31m/Users/Dan/miniconda3/envs/DSFP/lib/python3.6/site-packages/pluggy/manager.py\u001b[0m:61: in <lambda>\n",
      "\u001b[1m    firstresult=hook.spec.opts.get(\"firstresult\") if hook.spec else False,\u001b[0m\n",
      "\u001b[1m\u001b[31m/Users/Dan/miniconda3/envs/DSFP/lib/python3.6/site-packages/_pytest/runner.py\u001b[0m:115: in pytest_runtest_setup\n",
      "\u001b[1m    item.session._setupstate.prepare(item)\u001b[0m\n",
      "\u001b[1m\u001b[31m/Users/Dan/miniconda3/envs/DSFP/lib/python3.6/site-packages/_pytest/runner.py\u001b[0m:381: in prepare\n",
      "\u001b[1m    col.setup()\u001b[0m\n",
      "\u001b[1m\u001b[31m/Users/Dan/miniconda3/envs/DSFP/lib/python3.6/site-packages/_pytest/python.py\u001b[0m:497: in setup\n",
      "\u001b[1m    setup_module = _get_xunit_setup_teardown(self.obj, \"setUpModule\")\u001b[0m\n",
      "\u001b[1m\u001b[31m/Users/Dan/miniconda3/envs/DSFP/lib/python3.6/site-packages/_pytest/python.py\u001b[0m:248: in fget\n",
      "\u001b[1m    self._obj = obj = self._getobj()\u001b[0m\n",
      "\u001b[1m\u001b[31m/Users/Dan/miniconda3/envs/DSFP/lib/python3.6/site-packages/_pytest/python.py\u001b[0m:440: in _getobj\n",
      "\u001b[1m    return self._importtestmodule()\u001b[0m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <Package '/Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1/newfolder/git_test'>\n",
      "\n",
      "\u001b[1m    def _importtestmodule(self):\u001b[0m\n",
      "\u001b[1m        # we assume we are only called once per module\u001b[0m\n",
      "\u001b[1m        importmode = self.config.getoption(\"--import-mode\")\u001b[0m\n",
      "\u001b[1m        try:\u001b[0m\n",
      "\u001b[1m            mod = self.fspath.pyimport(ensuresyspath=importmode)\u001b[0m\n",
      "\u001b[1m        except SyntaxError:\u001b[0m\n",
      "\u001b[1m            raise self.CollectError(\u001b[0m\n",
      "\u001b[1m                _pytest._code.ExceptionInfo().getrepr(style=\"short\")\u001b[0m\n",
      "\u001b[1m            )\u001b[0m\n",
      "\u001b[1m        except self.fspath.ImportMismatchError:\u001b[0m\n",
      "\u001b[1m            e = sys.exc_info()[1]\u001b[0m\n",
      "\u001b[1m            raise self.CollectError(\u001b[0m\n",
      "\u001b[1m                \"import file mismatch:\\n\"\u001b[0m\n",
      "\u001b[1m                \"imported module %r has this __file__ attribute:\\n\"\u001b[0m\n",
      "\u001b[1m                \"  %s\\n\"\u001b[0m\n",
      "\u001b[1m                \"which is not the same as the test file we want to collect:\\n\"\u001b[0m\n",
      "\u001b[1m                \"  %s\\n\"\u001b[0m\n",
      "\u001b[1m                \"HINT: remove __pycache__ / .pyc files and/or use a \"\u001b[0m\n",
      "\u001b[1m                \"unique basename for your test file modules\" % e.args\u001b[0m\n",
      "\u001b[1m            )\u001b[0m\n",
      "\u001b[1m        except ImportError:\u001b[0m\n",
      "\u001b[1m            from _pytest._code.code import ExceptionInfo\u001b[0m\n",
      "\u001b[1m    \u001b[0m\n",
      "\u001b[1m            exc_info = ExceptionInfo()\u001b[0m\n",
      "\u001b[1m            if self.config.getoption(\"verbose\") < 2:\u001b[0m\n",
      "\u001b[1m                exc_info.traceback = exc_info.traceback.filter(filter_traceback)\u001b[0m\n",
      "\u001b[1m            exc_repr = (\u001b[0m\n",
      "\u001b[1m                exc_info.getrepr(style=\"short\")\u001b[0m\n",
      "\u001b[1m                if exc_info.traceback\u001b[0m\n",
      "\u001b[1m                else exc_info.exconly()\u001b[0m\n",
      "\u001b[1m            )\u001b[0m\n",
      "\u001b[1m            formatted_tb = safe_str(exc_repr)\u001b[0m\n",
      "\u001b[1m            raise self.CollectError(\u001b[0m\n",
      "\u001b[1m                \"ImportError while importing test module '{fspath}'.\\n\"\u001b[0m\n",
      "\u001b[1m                \"Hint: make sure your test modules/packages have valid Python names.\\n\"\u001b[0m\n",
      "\u001b[1m                \"Traceback:\\n\"\u001b[0m\n",
      "\u001b[1m>               \"{traceback}\".format(fspath=self.fspath, traceback=formatted_tb)\u001b[0m\n",
      "\u001b[1m            )\u001b[0m\n",
      "\u001b[1m\u001b[31mE           _pytest.nodes.Collector.CollectError: ImportError while importing test module '/Users/Dan/Documents/LSSTC-DSFP-Sessions/Session7/Day1/newfolder/git_test/__init__.py'.\u001b[0m\n",
      "\u001b[1m\u001b[31mE           Hint: make sure your test modules/packages have valid Python names.\u001b[0m\n",
      "\u001b[1m\u001b[31mE           Traceback:\u001b[0m\n",
      "\u001b[1m\u001b[31mE           __init__.py:1: in <module>\u001b[0m\n",
      "\u001b[1m\u001b[31mE               from .code import do_something\u001b[0m\n",
      "\u001b[1m\u001b[31mE           E   ImportError: cannot import name 'do_something'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/Users/Dan/miniconda3/envs/DSFP/lib/python3.6/site-packages/_pytest/python.py\u001b[0m:482: CollectError\n",
      "\n",
      "---------- coverage: platform darwin, python 3.6.7-final-0 -----------\n",
      "Name          Stmts   Miss  Cover\n",
      "---------------------------------\n",
      "__init__.py       1      0   100%\n",
      "code.py           5      2    60%\n",
      "---------------------------------\n",
      "TOTAL             6      2    67%\n",
      "\n",
      "\u001b[31m\u001b[1m=========================== 1 error in 0.78 seconds ============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%cd git_test\n",
    "!py.test --cov=git_test tests/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b\n",
    "\n",
    "This test has an intentional bug... but depending how you right the test you *might* not catch it...  Use unit tests to find it! (and then fix it...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing git_test/func_b.py\n"
     ]
    }
   ],
   "source": [
    "%%file git_test/func_b.py\n",
    "\n",
    "def function_b(value):\n",
    "    if value < 0:\n",
    "        return value - 1\n",
    "    else:\n",
    "        value2 = subfunction_b(value + 1)\n",
    "        return value + value2\n",
    "    \n",
    "def subfunction_b(inp):\n",
    "    vals_to_accum = []\n",
    "    for i in range(10):\n",
    "        vals_to_accum.append(inp ** (i/10))\n",
    "    if vals_to_accum[-1] > 2:\n",
    "        vals.append(100)\n",
    "    # really you would use numpy to do this kind of number-crunching... but we're doing this for the sake of example right now\n",
    "    return sum(vals_to_accum) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c\n",
    "\n",
    "There are (at least) *two* significant bugs in this code (one fairly apparent, one much more subtle).  Try to catch them both, and write a regression test that covers those cases once you've found them.\n",
    "\n",
    "One note about this function: in real code you're probably better off just using [the Angle object from `astropy.coordinates`](http://docs.astropy.org/en/stable/coordinates/angles.html).  But this example demonstrates one of the reasons *why* that was created, as it's very easy to write a buggy version of this code.\n",
    "\n",
    "*Hint: you might find it useful to use `astropy.coordinates.Angle` to create test cases...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing git_test/ang_to_sx.py\n"
     ]
    }
   ],
   "source": [
    "%%file git_test/ang_to_sx.py\n",
    "\n",
    "import math\n",
    "\n",
    "# know that to not have to worry about this, you should just use `astropy.coordinates`.\n",
    "def angle_to_sexigesimal(angle_in_degrees, decimals=3):\n",
    "    \"\"\"\n",
    "    Convert the given angle to a sexigesimal string of hours of RA.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    angle_in_degrees : float\n",
    "        A scalar angle, expressed in degrees\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    hms_str : str\n",
    "        The sexigesimal string giving the hours, minutes, and seconds of RA for the given `angle_in_degrees`\n",
    "        \n",
    "    \"\"\"\n",
    "    if math.floor(decimals) != decimals:\n",
    "        raise ValueError('decimals should be an integer!')\n",
    "    \n",
    "    hours_num = angle_in_degrees*24/180\n",
    "    hours = math.floor(hours_num)\n",
    "    \n",
    "    min_num = (hours_num - hours)*60\n",
    "    minutes = math.floor(min_num)\n",
    "    \n",
    "    seconds = (min_num - minutes)*60\n",
    "\n",
    "    format_string = '{}:{}:{:.' + str(decimals) + 'f}'\n",
    "    return format_string.format(hours, minutes, seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d\n",
    "\n",
    "*Hint: numpy has some useful functions in [numpy.testing](https://docs.scipy.org/doc/numpy/reference/routines.testing.html) for comparing arrays.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%file <yourproject>/<filename>.py #complete, or just use your editor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def function_d(array1=np.arange(10)*2, array2=np.arange(10), operation='-'):\n",
    "    \"\"\"\n",
    "    Makes a matrix where the [i,j]th element is array1[i] <operation> array2[j]\n",
    "    \"\"\"\n",
    "    if operation == '+':\n",
    "        return array1[:, np.newaxis] + array2\n",
    "    elif operation == '-':\n",
    "        return array1[:, np.newaxis] - array2\n",
    "    elif operation == '*':\n",
    "        return array1[:, np.newaxis] * array2\n",
    "    elif operation == '/':\n",
    "        return array1[:, np.newaxis] / array2\n",
    "    else:\n",
    "        raise ValueError('Unrecognized operation \"{}\"'.format(operation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Set up travis to run your tests whenever a change is made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a testing suite set up, you can try to turn on a continuous integration service to constantly check that any update you might send doesn't create a bug.  We will the [Travis-CI](https://travis-ci.org/) service for this purpose, as it has one of the lowest barriers to entry from Github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a: Ensure the test suite is passing locally\n",
    "\n",
    "Seems obvious, but it's easy to forget to check this and only later realize that all the trouble you thought you had setting up the CI service was because the tests were actually broken..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!py.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b: Set up an account on travis\n",
    "\n",
    "This turns out to be quite convenient.  If you go to the [Travis web site](https://travis-ci.org/), you'll see a \"Sign in with GitHub\" button.  You'll need to authorize Travis, but once you've done so it will automatically log you in and know which repositories are yours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c: Create a minimal ``.travis.yml`` file.\n",
    "\n",
    "Before we can activate travis on our repo, we need to tell travis a variety of metadata about what's in the repository and how to run it.  The template below should be sufficient for the simplest needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%file .travis.yml\n",
    "\n",
    "language: python\n",
    "python:\n",
    "  - \"3.6\"\n",
    "# command to install dependencies\n",
    "#install: \"pip install numpy\"  #uncomment this if your code depends on numpy or similar\n",
    "# command to run tests\n",
    "script: pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to commit and push this to github before proceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!git #complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d: activate Travis\n",
    "\n",
    "You can now click on your profile picture in the upper-right and choose \"accounts\".  You should see your repo listed there, presumably with a grey X next to it.  Click on the X, which should slide the button over and therefore activate travis on that repository. Once you've done this, you should be able to click on the name of the reposository in the travis accounts dashboard, popping up a window showing the build already in progress (if not, just be a bit patient)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the tests to complete.  If all is good you should see a green check next to the repository name.  Otherwise you'll need to go in and fix it and the tests will automatically trigger when you send a new update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3e: Break the build\n",
    "\n",
    "Make a small change to the repository to break a test.  If all else fails simply add the following test:\n",
    "\n",
    "```\n",
    "def test_fail():\n",
    "    assert False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push that change up and go look at travis.  It should automatically run the tests and result in them failing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3f: Have your neighbor fix your repo\n",
    "\n",
    "Challenge your nieghbor to find the bug and fix it.  Have them follow the Pull Request workflow, but do *not* merge the PR until Travis' tests have finished (they *should* run automatically, and leave note in the github PR page to that effect).  Once the tests have finished, they will tell you if the fix really does cure the bug.  If it does, merge it and say thank you.  If it doesn't, ask your neighbor to try updating their fix with the feedback from Travis...\n",
    "\n",
    "*Hint: it may be late in the day, but keep being nice!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Problem 1: Use py.test \"parametrization\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``py.test`` has a feature called test parametrization that can be extremely useful for writing easier-to-understand tests. The key idea is that you can use one simple test *function*, but with multiple inputs, and break that out into separate tests.  At first glance this might appear similar to just one test where you interate over lots of inputs, but it's actually much more useful because it doesn't stop at the *first* failure.  Rather it will run all the inputs ever time, helpinf you debug subtle problems where only certain inputs fail.\n",
    "\n",
    "For more info and how to actually *use* the feature, see [the py.test docs on the subject](https://docs.pytest.org/en/latest/parametrize.html).  In this challenge problem, try adapting the Problem 2 cases to use this feature. 2c and 2d are particularly amenable to this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Problem 2: Test-driven development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test-driven development is a radically different approach to designing code from what we're generally used to.  In test-driven design, you write the tests *first*.  That is, you write how you expect your code to behave before writing the code.\n",
    "\n",
    "For this problem, try experimenting with test-driven desgin.  Choose a problem (ideally from your science interests) where you know some clear cases that you could write tests for.  Write the full testing suite (using the techniques you developed above).  Then run the tests to ensure all the new ones are  failing due to lack of implementation, and then write the new code.  A few ideas are given below, but, again, for a real challenge try to come up with your own problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the location of Lagrange points for two arbitrary mass bodies.  (Good test cases are the Earth-Moon or Earth-Sun system, which you can probably find on wikipedia.)  Consider solving the problem numerically instead of with formulae you can look up, but use the formulae to concoct the test cases.\n",
    "* Write a function that uses one of the a clustering algorithm in [scikit-learn](http://scikit-learn.org/stable/modules/clustering.html) to identify the centers of two 2D gaussian point-clouds.  The tests are particularly easy to formulate before-hand because you know the right answer at the outset if you generate the point-clouds yourself."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
